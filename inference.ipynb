{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    if \"gpt2\" in model_path:\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    if \"gpt2\" in tokenizer_path:\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def generate_text(sequence, model_path='gpt2', max_length=20, num_beams=3, top_k=500, top_p=0.95):\n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        num_beams=num_beams,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love fruits in the summer but the taste in winter. If I were to eat one, that\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Oil price\"\n",
    "generate_text(sequence) # oil price for July June which had been low at as low as was originally stated Prices have since resumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = \"test_data/news_article_test.xlsx\"\n",
    "model_names = [\"EleutherAI/pythia-410m\", \"gpt2\", \"EleutherAI_popsongs\", \"gpt2_popsongs\", \"eleutherAI_articles\", \"gpt2_articles\"]\n",
    "for model_name in model_names:\n",
    "    df = pd.read_excel(name)\n",
    "    generated = []\n",
    "    for index, row in df.iterrows():\n",
    "        text = generate_text(row[\"sequence\"], model_name, 30)\n",
    "        generated.append(text)\n",
    "    df[f\"{model_name}_generated\"] = generated \n",
    "    df.to_excel(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a \n",
      "t-shirt that is made with a light-colored,\n",
      "cotton\n",
      "This is a \n",
      "trap?\n",
      "\n",
      "\n",
      "This is a \n",
      "call to \n",
      "I've read more than one hundred e-mail and\n",
      "This is a \n",
      "<a href=\"http://www.w3.org/TR/\n",
      "This is a \n",
      "case where \n",
      "(The value to be rounded is \n",
      "|R\n",
      "This is a \n",
      "variance analysis that looks at you and me, from our perspective, as\n",
      "This is a \n",
      "C++ class.\n",
      "\n",
      "I have to create a function that will take\n",
      "This is a \n",
      "\"natural key\" to the world's current financial world. Not really a\n",
      "This is a \n",
      "beginning; they grow and prosper as they are cherished and allowed to\n",
      "This is a \n",
      "case where the \n",
      "state of the \n",
      "state of the \n",
      "\n",
      "This is a \n",
      "<a href=\"http://www.w3.org/TR/\n",
      "This is a \n",
      "favorite of mine.  I have to say that I'm not a\n",
      "This is a \n",
      "case where I'm not sure what to do.\n",
      "\n",
      "A:\n",
      "\n",
      "This is a \n",
      "lot of work, and it's not going to be easy.  I\n",
      "This is a \n",
      "$2.1 million, $1.5 million charge, and the\n",
      "This is a \n",
      "dozen-year-old story.\n",
      "\n",
      "------\n",
      "michaelm\n",
      "This is a \n",
      "case in which you really have to look at the structure of the \n",
      "\n",
      "This is a \n",
      "glitch. \n",
      "We are going to go back to the \n",
      "\n",
      "This is a \n",
      "case where I would like to be able to do something like this:\n",
      "\n",
      "This is a \n",
      "<a href=\"http://www.w3.org/TR/\n",
      "This is a \n",
      "<a href=\"http://www.w3.org/TR/\n",
      "This is a \n",
      "<a href=\"http://www.w3.org/TR/\n",
      "This is a \n",
      "case in which you need to \n",
      "make sure that you are \n",
      "\n",
      "This is a \n",
      "<http://www.w3.org/Protocols/rfc\n",
      "This is a \n",
      "public class Test {\n",
      "\n",
      "    public static void main(String[] args)\n",
      "This is a \n",
      "lot of work.  Let me know if you have any questions.\n",
      "\n",
      "This is a \n",
      "case where you don't have to worry about the size of the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search\n",
    "sequence = \"This is a \"\n",
    "\n",
    "\n",
    "#max_length = [20, 30, 50]\n",
    "num_beams = [1, 3, 20]\n",
    "top_k = [50, 100, 500]\n",
    "top_p = [0.5, 0.95, 0.99]\n",
    "\n",
    "grid_res = {\"num_beams\": [], \"top_k\": [], \"top_p\": [], \"text\": []}\n",
    "\n",
    "for beam in num_beams:\n",
    "    for k in top_k:\n",
    "        for p in top_p:\n",
    "            text = generate_text(sequence, num_beams=beam, top_k=k, top_p=p)\n",
    "            #grid_res[\"max_length\"].append(length)\n",
    "            grid_res[\"num_beams\"].append(beam)\n",
    "            grid_res[\"top_k\"].append(k)\n",
    "            grid_res[\"top_p\"].append(p)\n",
    "            grid_res[\"text\"].append(text)\n",
    "            print(text)\n",
    "\n",
    "\n",
    "grid_res_df = pd.DataFrame(grid_res)\n",
    "grid_res_df.to_excel(\"grid_search_result.xlsx\", index=False)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['max_length', 'num_beams', 'top_k', 'top_p', 'text'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grid_res['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 40.8125, 'Eleuther_generated': 96.625, 'gpt2_generated': 105.1875, 'eleutherAI_popsongs_generated': 100.5625, 'gpt2_popsongs_generated': 100.3125, 'eleutherAI_articles_generated': 105.875, 'gpt2_articles_generated': 108.8125}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_excel(\"test_data/pop_song_test.xlsx\")\n",
    "res = {}\n",
    "for index, row in df.iterrows():\n",
    "    for column in df.columns:\n",
    "        if column not in res:\n",
    "            res[column] = len(row[column])\n",
    "        else:\n",
    "            res[column] += len(row[column])\n",
    "\n",
    "for key in res:\n",
    "    res[key] = res[key] / df.shape[0]\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
